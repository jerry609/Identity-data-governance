{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data():\n",
    "    user_activity_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\device.csv')\n",
    "    email_activity_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\email.csv')\n",
    "    file_activity_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\file.csv')\n",
    "    http_activity_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\http.csv')\n",
    "    department_info_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\DepartmentInfo.csv')\n",
    "    psychometric_df = pd.read_csv(r'D:\\dataset\\cmu-cert r4.2\\demo\\psychometric.csv')\n",
    "    return (user_activity_df, email_activity_df, file_activity_df, http_activity_df, department_info_df, psychometric_df)\n",
    "\n",
    "def clean_data(dfs):\n",
    "    # Replace 'None' string with NaN and drop NaN values\n",
    "    for df in dfs:\n",
    "        df.replace('None', pd.NA, inplace=True)\n",
    "        df.dropna(inplace=True)\n",
    "        if 'date' in df.columns:\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "        df.columns = map(str.lower, df.columns)\n",
    "    return dfs\n",
    "\n",
    "# 加载和清洗数据\n",
    "dfs = load_data()\n",
    "(user_activity_df, email_activity_df, file_activity_df, http_activity_df, department_info_df, psychometric_df) = clean_data(dfs)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def find_inconsistent_user_ids(dfs):\n",
    "    department_info_df = dfs[-2]\n",
    "    user_ids = set(department_info_df['user_id'])\n",
    "    inconsistent_user_ids = {}\n",
    "    for df_name, df in zip(['user_activity_df', 'email_activity_df', 'file_activity_df', 'http_activity_df', 'psychometric_df'],\n",
    "                           dfs[:-1]):\n",
    "        df_key = 'user_id' if 'user_id' in df.columns else 'user'\n",
    "        inconsistent_user_ids[df_name] = df[~df[df_key].isin(user_ids)][df_key].unique().tolist()\n",
    "    return inconsistent_user_ids\n",
    "\n",
    "# 查找不一致的用户ID\n",
    "inconsistent_user_ids = find_inconsistent_user_ids(dfs)\n"
   ],
   "id": "6a3582e303c9a704"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_triples(dfs):\n",
    "    (user_activity_df, email_activity_df, file_activity_df, http_activity_df, department_info_df, psychometric_df) = dfs\n",
    "    triples = []\n",
    "    def add_triple(source, relation, target):\n",
    "        if pd.notna(source) and pd.notna(target):\n",
    "            triples.append((source, relation, target))\n",
    "    \n",
    "    if 'user' in user_activity_df.columns:\n",
    "        for _, row in user_activity_df.iterrows():\n",
    "            add_triple(row['user'], '进行活动', row.get('activity', 'Unknown'))\n",
    "            add_triple(row['user'], '使用设备', row.get('pc', 'Unknown'))\n",
    "            if 'date' in row:\n",
    "                add_triple(row.get('activity', 'Unknown'), '发生在', row['date'])\n",
    "    \n",
    "    if 'user' in email_activity_df.columns:\n",
    "        for _, row in email_activity_df.iterrows():\n",
    "            add_triple(row['user'], '发送邮件到', row.get('to', 'Unknown'))\n",
    "            add_triple(row['user'], '使用设备', row.get('pc', 'Unknown'))\n",
    "            add_triple(row.get('id', 'Unknown'), '邮件大小', row.get('size', 'Unknown'))\n",
    "            add_triple(row.get('id', 'Unknown'), '附件数量', row.get('attachments', 'Unknown'))\n",
    "            add_triple(row.get('id', 'Unknown'), '邮件内容', row.get('content', 'Unknown'))\n",
    "    \n",
    "    if 'user' in file_activity_df.columns:\n",
    "        for _, row in file_activity_df.iterrows():\n",
    "            add_triple(row['user'], '访问文件', row.get('filename', 'Unknown'))\n",
    "            add_triple(row.get('filename', 'Unknown'), '文件内容', row.get('content', 'Unknown'))\n",
    "    \n",
    "    if 'user' in http_activity_df.columns:\n",
    "        for _, row in http_activity_df.iterrows():\n",
    "            add_triple(row['user'], '访问网址', row.get('url', 'Unknown'))\n",
    "            add_triple(row.get('url', 'Unknown'), '网址内容', row.get('content', 'Unknown'))\n",
    "    \n",
    "    if 'user_id' in department_info_df.columns:\n",
    "        for _, row in department_info_df.iterrows():\n",
    "            add_triple(row['user_id'], '属于部门', row.get('department', 'Unknown'))\n",
    "            add_triple(row['user_id'], '角色是', row.get('role', 'Unknown'))\n",
    "            add_triple(row['user_id'], '在业务单元', row.get('business_unit', 'Unknown'))\n",
    "            add_triple(row['user_id'], '在功能单元', row.get('functional_unit', 'Unknown'))\n",
    "    \n",
    "    if 'user_id' in psychometric_df.columns:\n",
    "        for _, row in psychometric_df.iterrows():\n",
    "            add_triple(row['user_id'], '开放性得分', row.get('o', 'Unknown'))\n",
    "            add_triple(row['user_id'], '尽责性得分', row.get('c', 'Unknown'))\n",
    "            add_triple(row['user_id'], '外向性得分', row.get('e', 'Unknown'))\n",
    "            add_triple(row['user_id'], '宜人性得分', row.get('a', 'Unknown'))\n",
    "            add_triple(row['user_id'], '神经质得分', row.get('n', 'Unknown'))\n",
    "    \n",
    "    return triples\n",
    "\n",
    "# 提取三元组\n",
    "triples = extract_triples(dfs)\n"
   ],
   "id": "f7cd7ca5d7658b6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "\n",
    "def build_graph(triples):\n",
    "    G = nx.DiGraph()\n",
    "    for triple in triples:\n",
    "        G.add_edge(triple[0], triple[2], label=triple[1], weight=1.0)\n",
    "    for u, v, d in G.edges(data=True):\n",
    "        try:\n",
    "            d['weight'] = float(d.get('weight', 1.0))\n",
    "        except ValueError:\n",
    "            d['weight'] = 1.0  # Default weight\n",
    "    return G\n",
    "\n",
    "def filter_graph(G):\n",
    "    filtered_nodes = {n for n in G if G.degree(n) > 5}\n",
    "    frozen_subgraph = nx.subgraph(G, filtered_nodes)\n",
    "    filtered_G = nx.DiGraph(frozen_subgraph)\n",
    "    isolated = list(nx.isolates(filtered_G))\n",
    "    filtered_G.remove_nodes_from(isolated)\n",
    "    return filtered_G\n",
    "\n",
    "# 构建图并过滤\n",
    "G = build_graph(triples)\n",
    "filtered_G = filter_graph(G)\n"
   ],
   "id": "ed9a07e7e643e3c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "def detect_communities(G):\n",
    "    return list(greedy_modularity_communities(G, weight='weight'))\n",
    "\n",
    "def visualize_graph(G, communities):\n",
    "    community_map = {node: i for i, community in enumerate(communities) for node in community}\n",
    "    \n",
    "    font_path = 'C:/Windows/Fonts/simhei.ttf'\n",
    "    font_prop = fm.FontProperties(fname=font_path)\n",
    "    plt.rcParams['font.family'] = font_prop.get_name()\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    pos = nx.spring_layout(G, k=0.3)\n",
    "    node_color = [community_map[node] for node in G.nodes()]\n",
    "    nx.draw(G, pos, with_labels=True, node_size=700, node_color=node_color, cmap=plt.cm.rainbow,\n",
    "            font_size=10, font_weight=\"bold\", arrowsize=15, font_family=font_prop.get_name())\n",
    "    edge_labels = nx.get_edge_attributes(G, 'label')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, font_family=font_prop.get_name())\n",
    "    plt.title(\"三元组网络图 - 社区检测\", fontproperties=font_prop)\n",
    "    plt.show()\n",
    "\n",
    "# 检测社区并可视化\n",
    "communities = detect_communities(filtered_G)\n",
    "visualize_graph(filtered_G, communities)\n"
   ],
   "id": "54aadfbd7a8938e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

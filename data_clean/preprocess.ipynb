{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-08T11:57:48.796653Z",
     "start_time": "2024-07-08T11:57:48.778710Z"
    }
   },
   "source": [
    "import hashlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T11:50:38.984972Z",
     "start_time": "2024-07-08T11:50:38.939246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def hash_email(email):\n",
    "    \"\"\" 使用SHA-256散列函数对邮箱进行散列 \"\"\"\n",
    "    return hashlib.sha256(email.encode()).hexdigest()\n",
    "\n",
    "def preprocess_user_data(department_info_path, psychometric_path, output_path):\n",
    "    # 加载数据\n",
    "    department_info = pd.read_csv(department_info_path)\n",
    "    psychometric = pd.read_csv(psychometric_path)\n",
    "\n",
    "    # 确保所有字段都存在并且是字符串类型\n",
    "    string_fields = ['employee_name', 'email', 'role', 'department', 'team', 'supervisor', 'business_unit']\n",
    "    for field in string_fields:\n",
    "        if field in department_info.columns:\n",
    "            department_info[field] = department_info[field].astype(str).str.strip()\n",
    "\n",
    "    department_info['user_type'] = 'Employee'  # 假设所有用户都是员工\n",
    "\n",
    "    # 处理 psychometric 数据\n",
    "    psychometric.columns = ['employee_name', 'user_id', 'o_score', 'c_score', 'e_score', 'a_score', 'n_score']\n",
    "    psychometric = psychometric.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "    # 合并数据\n",
    "    merged_data = pd.merge(department_info, psychometric, on='employee_name', how='left')\n",
    "    merged_data.fillna({'o_score': 0, 'c_score': 0, 'e_score': 0, 'a_score': 0, 'n_score': 0}, inplace=True)\n",
    "\n",
    "    # 添加日期字段\n",
    "    merged_data['join_date'] = pd.to_datetime('2021-01-01')  # 使用固定日期作为示例\n",
    "    merged_data['last_active'] = pd.to_datetime('now')\n",
    "\n",
    "    # 生成 user_id\n",
    "    merged_data['user_id'] = merged_data.apply(lambda x: hash_email(x['email']), axis=1)\n",
    "\n",
    "    # 导出数据到指定的输出路径\n",
    "    output_file = output_path + '/processed_user_data.csv'\n",
    "    merged_data.to_csv(output_file, index=False)\n",
    "    print(f\"Data processed and saved to {output_file}\")\n",
    "\n",
    "# 设置文件路径\n",
    "department_info_path = 'D:/Pycharm_pro/demo/pythonProject/data/DepartmentInfo.csv'\n",
    "psychometric_path = 'D:/Pycharm_pro/demo/pythonProject/data/psychometric.csv'\n",
    "output_path = 'D:/Pycharm_pro/demo/pythonProject/pro_data'\n",
    "\n",
    "# 处理数据\n",
    "preprocess_user_data(department_info_path, psychometric_path, output_path)\n"
   ],
   "id": "1646753b31e36ed1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed and saved to D:/Pycharm_pro/demo/pythonProject/pro_data/processed_user_data.csv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T12:02:32.021163Z",
     "start_time": "2024-07-08T12:02:31.990249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_data_path = 'D:/Pycharm_pro/demo/pythonProject/pro_data/processed_user_data.csv'\n",
    "department_data_path = 'D:/Pycharm_pro/demo/pythonProject/data/DepartmentInfo.csv'\n",
    "\n",
    "# 加载数据\n",
    "user_df = pd.read_csv(user_data_path)\n",
    "department_df = pd.read_csv(department_data_path)\n",
    "\n",
    "# 提取user_id\n",
    "user_ids = user_df['user_id'].unique()\n",
    "\n",
    "# 生成用户关系\n",
    "def generate_user_relations(user_ids, num_relations=100):\n",
    "    relations = []\n",
    "    for _ in range(num_relations):\n",
    "        users_pair = np.random.choice(user_ids, size=2, replace=False)\n",
    "        relation_id = str(uuid.uuid4())\n",
    "        relation_type = np.random.choice(['colleague', 'supervisor', 'subordinate'])\n",
    "        strength = np.random.uniform(0, 1)  # 随机生成关系强度\n",
    "        \n",
    "        relations.append({\n",
    "            'relation_id': relation_id,\n",
    "            'user_id_1': users_pair[0],\n",
    "            'user_id_2': users_pair[1],\n",
    "            'relation_type': relation_type,\n",
    "            'strength': strength\n",
    "        })\n",
    "    return pd.DataFrame(relations)\n",
    "\n",
    "# 生成并保存用户关系\n",
    "user_relations_df = generate_user_relations(user_ids)\n",
    "user_relations_df.to_csv('D:/Pycharm_pro/demo/pythonProject/pro_data/user_relations.csv', index=False)\n"
   ],
   "id": "152eae04fcc1560c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T12:55:18.372403Z",
     "start_time": "2024-07-08T12:55:18.333472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# 文件路径\n",
    "device_path = 'D:/Pycharm_pro/demo/pythonProject/data/device.csv'\n",
    "email_path = 'D:/Pycharm_pro/demo/pythonProject/data/email.csv'\n",
    "file_path = 'D:/Pycharm_pro/demo/pythonProject/data/file.csv'\n",
    "http_path = 'D:/Pycharm_pro/demo/pythonProject/data/http.csv'\n",
    "logon_path = 'D:/Pycharm_pro/demo/pythonProject/data/logon.csv'\n",
    "output_path = 'D:/Pycharm_pro/demo/pythonProject/pro_data/activity_data.csv'\n",
    "\n",
    "date_format = \"%Y/%m/%d %H:%M\" # 假设的日期时间格式\n",
    "data_frames = []\n",
    "for path in [device_path, email_path, file_path, http_path, logon_path]:\n",
    "    df = pd.read_csv(path)\n",
    "    df['date'] = pd.to_datetime(df['date'], format=date_format, errors='coerce') # 将错误的日期转为NaT\n",
    "    data_frames.append(df)\n",
    "\n",
    "# 加载数据\n",
    "device_df = pd.read_csv(device_path)\n",
    "email_df = pd.read_csv(email_path)\n",
    "file_df = pd.read_csv(file_path)\n",
    "http_df = pd.read_csv(http_path)\n",
    "logon_df = pd.read_csv(logon_path)\n",
    "\n",
    "# 重命名 'pc' 列为 'pc_id'\n",
    "for df in [device_df, email_df, file_df, http_df, logon_df]:\n",
    "    if 'pc' in df.columns:\n",
    "        df.rename(columns={'pc': 'pc_id'}, inplace=True)\n",
    "\n",
    "# 为每个DataFrame添加 'user_id' 列（如果不存在）\n",
    "for df in [email_df, file_df, http_df, logon_df, device_df]:\n",
    "    if 'user' in df.columns:\n",
    "        df.rename(columns={'user': 'user_id'}, inplace=True)\n",
    "\n",
    "# 创建 pc_id 到 user_id 的映射并更新 user_id\n",
    "pc_to_user = device_df.set_index('pc_id')['user_id'].to_dict()\n",
    "for df in [email_df, file_df, http_df, logon_df]:\n",
    "    df['user_id'] = df['pc_id'].map(pc_to_user).fillna(df['user_id'])\n",
    "\n",
    "# 确保所有DataFrame都有必需的列\n",
    "default_columns = ['user_id', 'pc_id', 'device_type', 'location']\n",
    "defaults = {'user_id': 'unknown', 'pc_id': 'unknown', 'device_type': 'unknown', 'location': 'unknown'}\n",
    "\n",
    "data_frames = [device_df, email_df, file_df, http_df, logon_df]\n",
    "for df in data_frames:\n",
    "    for col, default in defaults.items():\n",
    "        if col not in df.columns:\n",
    "            df[col] = default  # 添加缺失列并使用默认值填充\n",
    "            \n",
    "# 为每个DataFrame指定活动类型\n",
    "device_df['activity_type'] = 'device'\n",
    "email_df['activity_type'] = 'email'\n",
    "file_df['activity_type'] = 'file'\n",
    "http_df['activity_type'] = 'http'\n",
    "logon_df['activity_type'] = 'logon'\n",
    "\n",
    "# 合并数据\n",
    "all_data = pd.concat([device_df, email_df, file_df, http_df, logon_df], ignore_index=True)\n",
    "\n",
    "# 添加其他必要字段\n",
    "all_data['activity_id'] = [str(uuid.uuid4()) for _ in range(len(all_data))]\n",
    "all_data['datetime'] = pd.to_datetime(all_data['date'])  # 假设所有数据文件都有 'date' 字段\n",
    "all_data['action_details'] = 'Details about the action'\n",
    "all_data['risk_level'] = 'Low'\n",
    "all_data['correlated_id'] = all_data['activity_id']\n",
    "all_data['target_user_id'] = all_data['user_id']\n",
    "\n",
    "# 准备最终的数据表格\n",
    "activity_columns = [\n",
    "    'activity_id', 'datetime', 'user_id', 'pc_id', 'device_type', \n",
    "    'location', 'activity_type', 'action_details', 'risk_level', \n",
    "    'correlated_id', 'target_user_id'\n",
    "]\n",
    "activity_df = all_data[activity_columns]\n",
    "\n",
    "# 保存到CSV文件\n",
    "activity_df.to_csv(output_path, index=False)\n",
    "print(\"Activity data processed and saved successfully.\")\n"
   ],
   "id": "b3ccde80e6e9a988",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity data processed and saved successfully.\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T13:40:17.287643Z",
     "start_time": "2024-07-08T13:40:17.261730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# 定义文件路径\n",
    "file_paths = {\n",
    "    'device': 'D:/Pycharm_pro/demo/pythonProject/data/device.csv',\n",
    "    'email': 'D:/Pycharm_pro/demo/pythonProject/data/email.csv',\n",
    "    'file': 'D:/Pycharm_pro/demo/pythonProject/data/file.csv',\n",
    "    'http': 'D:/Pycharm_pro/demo/pythonProject/data/http.csv',\n",
    "    'logon': 'D:/Pycharm_pro/demo/pythonProject/data/logon.csv'\n",
    "}\n",
    "output_path = 'D:/Pycharm_pro/demo/pythonProject/pro_data/activity.csv'\n",
    "\n",
    "# 需要确保存在的列\n",
    "required_columns = ['user_id', 'pc_id', 'device_type', 'location', 'activity_type']\n",
    "\n",
    "# 加载和处理数据\n",
    "data_frames = []\n",
    "for key, path in file_paths.items():\n",
    "    df = pd.read_csv(path)\n",
    "    if 'pc' in df.columns:\n",
    "        df.rename(columns={'pc': 'pc_id'}, inplace=True)\n",
    "    if 'user' in df.columns:\n",
    "        df.rename(columns={'user': 'user_id'}, inplace=True)\n",
    "    \n",
    "    # 设置缺失的列和默认值\n",
    "    for column in required_columns:\n",
    "        if column not in df.columns:\n",
    "            df[column] = 'unknown'  # 使用 'unknown' 或其他适当的默认值填充\n",
    "    \n",
    "    df['user_id'] = df.get('user_id', 'unknown')  # Set default user_id if missing\n",
    "    df['activity_type'] = key\n",
    "    df['datetime'] = pd.to_datetime(df['date'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "    data_frames.append(df)\n",
    "\n",
    "# 合并所有数据帧\n",
    "all_data = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# 添加额外必要的字段\n",
    "all_data['activity_id'] = [str(uuid.uuid4()) for _ in range(len(all_data))]\n",
    "all_data['action_details'] = 'Details about the action'\n",
    "all_data['risk_level'] = 'Low'\n",
    "all_data['correlated_id'] = all_data['activity_id']\n",
    "all_data['target_user_id'] = all_data['user_id']\n",
    "\n",
    "# 定义最终数据帧的列并保存到 CSV\n",
    "activity_columns = [\n",
    "    'activity_id', 'datetime', 'user_id', 'pc_id', 'device_type',\n",
    "    'location', 'activity_type', 'action_details', 'risk_level',\n",
    "    'correlated_id', 'target_user_id'\n",
    "]\n",
    "try:\n",
    "    activity_df = all_data[activity_columns]\n",
    "    activity_df.to_csv(output_path, index=False)\n",
    "    print(\"Activity data processed and saved successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to save data: {e}\")\n"
   ],
   "id": "6271871d89c49e26",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity data processed and saved successfully.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a83dc9a6fa1d63c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
